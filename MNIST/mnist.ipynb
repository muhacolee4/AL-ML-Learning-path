{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem definition\n",
    "The aim of this code is to build a machine learning model that can classify images of handwritten digits into their respective numerical values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    " The dataset used for this task is the MNIST dataset, which is a collection of 70,000 grayscale images of handwritten digits, each of size 28x28 pixels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code first imports the required libraries, including TensorFlow, NumPy, and Matplotlib. The MNIST dataset is then loaded using the TensorFlow Keras library. The dataset is split into a training set and a test set, each containing images and their respective labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the require libraries\n",
    "import os, cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras.api._v2.keras.datasets.mnist' from 'c:\\\\Users\\\\Engr M2j\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\keras\\\\api\\\\_v2\\\\keras\\\\datasets\\\\mnist\\\\__init__.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset\n",
    "mnist=tf.keras.datasets.mnist\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test,y_test)=mnist.load_data()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below preprocess the data by normalizing the pixel values of the images. This is done to ensure that the pixel values fall within a common range, making it easier for the model to learn and generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "#normalizing the x_train and x_test\n",
    "\n",
    "x_train=tf.keras.utils.normalize(x_train,axis=1)\n",
    "x_test=tf.keras.utils.normalize(x_test,axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model\n",
    "A feedforward neural network model is built using the TensorFlow Keras Sequential API. The model has three dense layers, with the first layer being a Flatten layer that flattens the 2D input images into a 1D array. The two hidden layers have 128 neurons each and use the ReLU activation function. The output layer has 10 neurons (one for each digit from 0 to 9) and uses the softmax activation function to produce a probability distribution over the classes.\n",
    "\n",
    "# simple feedforward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buiding the models\n",
    "model=tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compiling the model\n",
    "The model is then compiled using the Adam optimizer, sparse categorical cross-entropy loss function, and accuracy as the metric for evaluation. The summary of the model is printed to the console, which provides information about the number of parameters in the model and the layer-wise architecture of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "\n",
    "Finally, the model is trained on the training data for 50 epochs using the fit() method. During training, the model learns to minimize the loss function and maximize the accuracy on the training data. The trained model can then be used to predict the classes of new images in the test set. The model gave an 0.9881."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 9s 3ms/step - loss: 1.6308 - accuracy: 0.8820\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3623 - accuracy: 0.9330\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2299 - accuracy: 0.9443\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1725 - accuracy: 0.9547\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1418 - accuracy: 0.9611\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1267 - accuracy: 0.9653\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1159 - accuracy: 0.9678\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1053 - accuracy: 0.9702\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1012 - accuracy: 0.9722\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0914 - accuracy: 0.9755\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0871 - accuracy: 0.9759\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0893 - accuracy: 0.9763\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0837 - accuracy: 0.9778\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0803 - accuracy: 0.9789\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0795 - accuracy: 0.9799\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0718 - accuracy: 0.9812\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0673 - accuracy: 0.9831\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0684 - accuracy: 0.9829\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0691 - accuracy: 0.9825\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0697 - accuracy: 0.9830\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0617 - accuracy: 0.9848\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0686 - accuracy: 0.9839\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0584 - accuracy: 0.9855\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0637 - accuracy: 0.9848\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0596 - accuracy: 0.9860\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0569 - accuracy: 0.9859\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0581 - accuracy: 0.9861\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0580 - accuracy: 0.9868\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0587 - accuracy: 0.9862\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0582 - accuracy: 0.9871\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0502 - accuracy: 0.9884\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0684 - accuracy: 0.9859\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0515 - accuracy: 0.9884\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0507 - accuracy: 0.9884\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0570 - accuracy: 0.9879\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0445 - accuracy: 0.9900\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0570 - accuracy: 0.9878\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0566 - accuracy: 0.9880\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0487 - accuracy: 0.9898\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0516 - accuracy: 0.9890\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0465 - accuracy: 0.9891\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0490 - accuracy: 0.9895\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0619 - accuracy: 0.9889\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0551 - accuracy: 0.9893\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0480 - accuracy: 0.9902\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0542 - accuracy: 0.9885\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0593 - accuracy: 0.9880\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0474 - accuracy: 0.9896\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0643 - accuracy: 0.9880\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0645 - accuracy: 0.9881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1657a9875b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(x_train,y_train, epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
