{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem definition\n",
    "The aim of this code is to build a machine learning model that can classify images of handwritten digits into their respective numerical values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    " The dataset used for this task is the MNIST dataset, which is a collection of 70,000 grayscale images of handwritten digits, each of size 28x28 pixels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code first imports the required libraries, including TensorFlow, NumPy, and Matplotlib. The MNIST dataset is then loaded using the TensorFlow Keras library. The dataset is split into a training set and a test set, each containing images and their respective labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the require libraries\n",
    "import os, cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras.api._v2.keras.datasets.mnist' from 'c:\\\\Users\\\\Engr M2j\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\keras\\\\api\\\\_v2\\\\keras\\\\datasets\\\\mnist\\\\__init__.py'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset\n",
    "mnist=tf.keras.datasets.mnist\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test,y_test)=mnist.load_data()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below preprocess the data by normalizing the pixel values of the images. This is done to ensure that the pixel values fall within a common range, making it easier for the model to learn and generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "#normalizing the x_train and x_test\n",
    "\n",
    "x_train=tf.keras.utils.normalize(x_train,axis=1)\n",
    "x_test=tf.keras.utils.normalize(x_test,axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model\n",
    "A feedforward neural network model is built using the TensorFlow Keras Sequential API. The model has three dense layers, with the first layer being a Flatten layer that flattens the 2D input images into a 1D array. The two hidden layers have 128 neurons each and use the ReLU activation function. The output layer has 10 neurons (one for each digit from 0 to 9) and uses the softmax activation function to produce a probability distribution over the classes.\n",
    "\n",
    "# simple feedforward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buiding the models\n",
    "model=tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compiling the model\n",
    "The model is then compiled using the Adam optimizer, sparse categorical cross-entropy loss function, and accuracy as the metric for evaluation. The summary of the model is printed to the console, which provides information about the number of parameters in the model and the layer-wise architecture of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151,306\n",
      "Trainable params: 151,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "\n",
    "Finally, the model is trained on the training data for 50 epochs using the fit() method. During training, the model learns to minimize the loss function and maximize the accuracy on the training data. The trained model can then be used to predict the classes of new images in the test set. \n",
    "# Modifying Training Parameter\n",
    "The model gave an accuracy of 0.9881 when training with two hidden layers and 50 epochs. There was a great improvement from 0.9881 to 0.9987 when the hidden layers was increased to 4 layers and 50 epochs. When the hidden layers was increased to 8, the accuracy reduced to 0.9984. The hidden layers was reduced to 4 and 200 epochs which gave the best accuracy of 0.9997."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 0.2492 - accuracy: 0.9251\n",
      "Epoch 2/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1070 - accuracy: 0.9679\n",
      "Epoch 3/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0748 - accuracy: 0.9770\n",
      "Epoch 4/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0603 - accuracy: 0.9812\n",
      "Epoch 5/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0474 - accuracy: 0.9851\n",
      "Epoch 6/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0415 - accuracy: 0.9865\n",
      "Epoch 7/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0341 - accuracy: 0.9896\n",
      "Epoch 8/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0315 - accuracy: 0.9901\n",
      "Epoch 9/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0275 - accuracy: 0.9914\n",
      "Epoch 10/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0249 - accuracy: 0.9918\n",
      "Epoch 11/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0221 - accuracy: 0.9932\n",
      "Epoch 12/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0196 - accuracy: 0.9938\n",
      "Epoch 13/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0172 - accuracy: 0.9945\n",
      "Epoch 14/200\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0168 - accuracy: 0.9946\n",
      "Epoch 15/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0164 - accuracy: 0.9947\n",
      "Epoch 16/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0154 - accuracy: 0.9955\n",
      "Epoch 17/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0135 - accuracy: 0.9959\n",
      "Epoch 18/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0131 - accuracy: 0.9960\n",
      "Epoch 19/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0129 - accuracy: 0.9963\n",
      "Epoch 20/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0125 - accuracy: 0.9963\n",
      "Epoch 21/200\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0108 - accuracy: 0.9970\n",
      "Epoch 22/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0125 - accuracy: 0.9964\n",
      "Epoch 23/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0117 - accuracy: 0.9966\n",
      "Epoch 24/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0094 - accuracy: 0.9972\n",
      "Epoch 25/200\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0099 - accuracy: 0.9971\n",
      "Epoch 26/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0104 - accuracy: 0.9972\n",
      "Epoch 27/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0107 - accuracy: 0.9970\n",
      "Epoch 28/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0100 - accuracy: 0.9972\n",
      "Epoch 29/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0094 - accuracy: 0.9974\n",
      "Epoch 30/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0101 - accuracy: 0.9974\n",
      "Epoch 31/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0093 - accuracy: 0.9976\n",
      "Epoch 32/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0078 - accuracy: 0.9978\n",
      "Epoch 33/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0087 - accuracy: 0.9976\n",
      "Epoch 34/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0084 - accuracy: 0.9977\n",
      "Epoch 35/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0073 - accuracy: 0.9982\n",
      "Epoch 36/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0094 - accuracy: 0.9976\n",
      "Epoch 37/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0079 - accuracy: 0.9979\n",
      "Epoch 38/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0074 - accuracy: 0.9983\n",
      "Epoch 39/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0091 - accuracy: 0.9976\n",
      "Epoch 40/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0065 - accuracy: 0.9980\n",
      "Epoch 41/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0063 - accuracy: 0.9984\n",
      "Epoch 42/200\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0069 - accuracy: 0.9984\n",
      "Epoch 43/200\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0078 - accuracy: 0.9980\n",
      "Epoch 44/200\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0069 - accuracy: 0.9983\n",
      "Epoch 45/200\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0086 - accuracy: 0.9976\n",
      "Epoch 46/200\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0056 - accuracy: 0.9984\n",
      "Epoch 47/200\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0081 - accuracy: 0.9981\n",
      "Epoch 48/200\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0048 - accuracy: 0.9987\n",
      "Epoch 49/200\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0094 - accuracy: 0.9977\n",
      "Epoch 50/200\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0053 - accuracy: 0.9987\n",
      "Epoch 51/200\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0075 - accuracy: 0.9982\n",
      "Epoch 52/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0046 - accuracy: 0.9987\n",
      "Epoch 53/200\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0097 - accuracy: 0.9979\n",
      "Epoch 54/200\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0052 - accuracy: 0.9987\n",
      "Epoch 55/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0079 - accuracy: 0.9981\n",
      "Epoch 56/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0078 - accuracy: 0.9987\n",
      "Epoch 57/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0091 - accuracy: 0.9984\n",
      "Epoch 58/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0061 - accuracy: 0.9986\n",
      "Epoch 59/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0057 - accuracy: 0.9986\n",
      "Epoch 60/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0072 - accuracy: 0.9984\n",
      "Epoch 61/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 62/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0053 - accuracy: 0.9986\n",
      "Epoch 63/200\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0082 - accuracy: 0.9983\n",
      "Epoch 64/200\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0053 - accuracy: 0.9987\n",
      "Epoch 65/200\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0049 - accuracy: 0.9989\n",
      "Epoch 66/200\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0101 - accuracy: 0.9978\n",
      "Epoch 67/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0043 - accuracy: 0.9990\n",
      "Epoch 68/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0090 - accuracy: 0.9982\n",
      "Epoch 69/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0067 - accuracy: 0.9987\n",
      "Epoch 70/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0047 - accuracy: 0.9989\n",
      "Epoch 71/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0036 - accuracy: 0.9992\n",
      "Epoch 72/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0059 - accuracy: 0.9986\n",
      "Epoch 73/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0075 - accuracy: 0.9985\n",
      "Epoch 74/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0070 - accuracy: 0.9985\n",
      "Epoch 75/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0062 - accuracy: 0.9989\n",
      "Epoch 76/200\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0078 - accuracy: 0.9986\n",
      "Epoch 77/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0055 - accuracy: 0.9990\n",
      "Epoch 78/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0072 - accuracy: 0.9989\n",
      "Epoch 79/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0063 - accuracy: 0.9987\n",
      "Epoch 80/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0073 - accuracy: 0.9985\n",
      "Epoch 81/200\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0035 - accuracy: 0.9992\n",
      "Epoch 82/200\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0054 - accuracy: 0.9989\n",
      "Epoch 83/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0062 - accuracy: 0.9988\n",
      "Epoch 84/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0064 - accuracy: 0.9987\n",
      "Epoch 85/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0073 - accuracy: 0.9985\n",
      "Epoch 86/200\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0065 - accuracy: 0.9989\n",
      "Epoch 87/200\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0061 - accuracy: 0.9989\n",
      "Epoch 88/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0054 - accuracy: 0.9988\n",
      "Epoch 89/200\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0060 - accuracy: 0.9988\n",
      "Epoch 90/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0054 - accuracy: 0.9990\n",
      "Epoch 91/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0056 - accuracy: 0.9989\n",
      "Epoch 92/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0073 - accuracy: 0.9987\n",
      "Epoch 93/200\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0052 - accuracy: 0.9991\n",
      "Epoch 94/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0035 - accuracy: 0.9991\n",
      "Epoch 95/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0051 - accuracy: 0.9990\n",
      "Epoch 96/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "Epoch 97/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0034 - accuracy: 0.9992\n",
      "Epoch 98/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0060 - accuracy: 0.9989\n",
      "Epoch 99/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0045 - accuracy: 0.9992\n",
      "Epoch 100/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0067 - accuracy: 0.9990\n",
      "Epoch 101/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0030 - accuracy: 0.9995\n",
      "Epoch 102/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0090 - accuracy: 0.9986\n",
      "Epoch 103/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0061 - accuracy: 0.9988\n",
      "Epoch 104/200\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0047 - accuracy: 0.9993\n",
      "Epoch 105/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0037 - accuracy: 0.9992\n",
      "Epoch 106/200\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0058 - accuracy: 0.9989\n",
      "Epoch 107/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0054 - accuracy: 0.9990\n",
      "Epoch 108/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0045 - accuracy: 0.9992\n",
      "Epoch 109/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0071 - accuracy: 0.9988\n",
      "Epoch 110/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 111/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0064 - accuracy: 0.9993\n",
      "Epoch 112/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0053 - accuracy: 0.9990\n",
      "Epoch 113/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0054 - accuracy: 0.9989\n",
      "Epoch 114/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0043 - accuracy: 0.9990\n",
      "Epoch 115/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0058 - accuracy: 0.9990\n",
      "Epoch 116/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0036 - accuracy: 0.9991\n",
      "Epoch 117/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0056 - accuracy: 0.9989\n",
      "Epoch 118/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0027 - accuracy: 0.9995\n",
      "Epoch 119/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "Epoch 120/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0085 - accuracy: 0.9988\n",
      "Epoch 121/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0045 - accuracy: 0.9991\n",
      "Epoch 122/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 123/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0053 - accuracy: 0.9989\n",
      "Epoch 124/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0073 - accuracy: 0.9991\n",
      "Epoch 125/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0049 - accuracy: 0.9992\n",
      "Epoch 126/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0055 - accuracy: 0.9990\n",
      "Epoch 127/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0053 - accuracy: 0.9991\n",
      "Epoch 128/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0034 - accuracy: 0.9994\n",
      "Epoch 129/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0038 - accuracy: 0.9992\n",
      "Epoch 130/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0034 - accuracy: 0.9994\n",
      "Epoch 131/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0069 - accuracy: 0.9990\n",
      "Epoch 132/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0037 - accuracy: 0.9992\n",
      "Epoch 133/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0041 - accuracy: 0.9992\n",
      "Epoch 134/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 135/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0073 - accuracy: 0.9991\n",
      "Epoch 136/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0064 - accuracy: 0.9991\n",
      "Epoch 137/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0030 - accuracy: 0.9998\n",
      "Epoch 138/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0056 - accuracy: 0.9990\n",
      "Epoch 139/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0049 - accuracy: 0.9990\n",
      "Epoch 140/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0065 - accuracy: 0.9990\n",
      "Epoch 141/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 142/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0045 - accuracy: 0.9994\n",
      "Epoch 143/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0052 - accuracy: 0.9991\n",
      "Epoch 144/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 145/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0025 - accuracy: 0.9996\n",
      "Epoch 146/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0062 - accuracy: 0.9987\n",
      "Epoch 147/200\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 148/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0073 - accuracy: 0.9990\n",
      "Epoch 149/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 150/200\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0052 - accuracy: 0.9993\n",
      "Epoch 151/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0070 - accuracy: 0.9993\n",
      "Epoch 152/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0038 - accuracy: 0.9991\n",
      "Epoch 153/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0054 - accuracy: 0.9995\n",
      "Epoch 154/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0029 - accuracy: 0.9992\n",
      "Epoch 155/200\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 156/200\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 157/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0077 - accuracy: 0.9989\n",
      "Epoch 158/200\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0038 - accuracy: 0.9993\n",
      "Epoch 159/200\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0077 - accuracy: 0.9989\n",
      "Epoch 160/200\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0042 - accuracy: 0.9993\n",
      "Epoch 161/200\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0038 - accuracy: 0.9995\n",
      "Epoch 162/200\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0034 - accuracy: 0.9994\n",
      "Epoch 163/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0074 - accuracy: 0.9992\n",
      "Epoch 164/200\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0043 - accuracy: 0.9993\n",
      "Epoch 165/200\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0047 - accuracy: 0.9995\n",
      "Epoch 166/200\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 167/200\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 168/200\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0043 - accuracy: 0.9993\n",
      "Epoch 169/200\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0114 - accuracy: 0.9991\n",
      "Epoch 170/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 171/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0046 - accuracy: 0.9992\n",
      "Epoch 172/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 9.6554e-04 - accuracy: 0.9999\n",
      "Epoch 173/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 5.2080e-04 - accuracy: 0.9999\n",
      "Epoch 174/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0084 - accuracy: 0.9985\n",
      "Epoch 175/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0078 - accuracy: 0.9989\n",
      "Epoch 176/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0045 - accuracy: 0.9993\n",
      "Epoch 177/200\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 178/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0078 - accuracy: 0.9991\n",
      "Epoch 179/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 180/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 181/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0053 - accuracy: 0.9994\n",
      "Epoch 182/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0038 - accuracy: 0.9994\n",
      "Epoch 183/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0018 - accuracy: 0.9997\n",
      "Epoch 184/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0047 - accuracy: 0.9991\n",
      "Epoch 185/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0022 - accuracy: 0.9997\n",
      "Epoch 186/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0037 - accuracy: 0.9994\n",
      "Epoch 187/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0072 - accuracy: 0.9991\n",
      "Epoch 188/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 189/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 3.9244e-04 - accuracy: 0.9999\n",
      "Epoch 190/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0094 - accuracy: 0.9991\n",
      "Epoch 191/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0024 - accuracy: 0.9996\n",
      "Epoch 192/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0057 - accuracy: 0.9993\n",
      "Epoch 193/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0072 - accuracy: 0.9992\n",
      "Epoch 194/200\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0040 - accuracy: 0.9993\n",
      "Epoch 195/200\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0029 - accuracy: 0.9996\n",
      "Epoch 196/200\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 197/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0056 - accuracy: 0.9993\n",
      "Epoch 198/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 199/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0077 - accuracy: 0.9991\n",
      "Epoch 200/200\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16509308d30>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(x_train,y_train, epochs=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
